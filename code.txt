## Python Chatbot Code Example

Hereâ€™s an example of the Python code used for the chatbot:

```python
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer
import gradio as gr

# Load pre-trained Hugging Face model for Python tasks
model_name = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)
text_generator = pipeline("text-generation", model=model, tokenizer=tokenizer)

# Function to handle chatbot tasks: error correction, Q&A, code generation, and algorithm generation
def python_chatbot(user_input, task):
    """
    Handles Python-specific chatbot tasks.

    Parameters:
    - user_input: str, the input text from the user.
    - task: str, the type of task (e.g., "Error Correction", "Q&A", "Code Generation", "Generate Algorithm").

    Returns:
    - str: The generated response.
    """
    # Construct prompts based on the selected task
    if task == "Error Correction":
        prompt = f"Correct the following Python code and explain the correction:\n{user_input}\nCorrected Code and Explanation:"
    elif task == "Q&A":
        prompt = f"You are a Python expert. Answer the following question clearly and concisely:\nQuestion: {user_input}\nAnswer:"
    elif task == "Code Generation":
        prompt = f"Generate Python code for the following request:\n{user_input}\nGenerated Python Code:"
    elif task == "Generate Algorithm":
        prompt = f"Analyze the following Python program and generate a step-by-step algorithm for it:\n{user_input}\nAlgorithm:"
    else:
        return "Invalid task selected."

    # Generate response using the model
    response = text_generator(
        prompt,
        max_length=500,
        num_return_sequences=1,
        pad_token_id=tokenizer.eos_token_id,
        temperature=0.7,
        top_p=0.85
    )[0]["generated_text"]

    # Extract only the generated response beyond the prompt
    return response[len(prompt):].strip()
